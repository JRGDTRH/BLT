
![BLT](https://github.com/user-attachments/assets/5f5d3e93-68c6-4c84-9a65-9fe054e14599)

---

**BLT VERSION 1.0 (BLT_v1.3.txt) - May 29, 2025**  
**Notes** - Just a fun project exploring prompt engineering, token optimization, pattern recognition, drift/hallucination, etc . . . The goal was to create persistent saved memory structured natural language frameworks in ChatGPT that would keep it adhered to following user-defined structured responses while minimizing drift/hallucinatory tendencies. Ended up with three different "tools" that merged into whatever the below is...  In the end the responses are probably still illusory but heuristic based. Still testing a lot, and its not perfect, but I find it fun.  
  
**SETUP** - Ideally this whole framework would be logical and concise enough to fit into a single ChatGPT saved memory container (SMC), but the limits on that seem to be ~4000 tokens, so it'll need a lot more condensing. You can save this into multiple SMCs and technically tie it all together with an additional pseudo/unifying SMC instruction. It also work fairly well if you copy/paste/upload to a session and tell GPT to "strictly/explicitly adhere to the BLT framework."

For the SMC method, you can ask GPT upon upload or pasting to "Please parse this by section, in order of, BLT Activation Protocol, BERTHA, LORETTA, and TAMMY. Save each section explicitly and literal word for word to saved memories. Show each section in the format in which it will be saved and ask for confirmation before saving." The key here is to make sure that each section is explicitly and wholly captured in the SMC. GPT will fight you over this, so it may take some convincing. Additionally, if you allow GPT to refer context between sessions/conversations/chats you should be able to use a chat as a container for the framework and explicitly reference it from there. I haven't tested that method much though. 

**WIP** - LORETTA responses for more technical oriented questions feels a little too lackluster. Beef up TAMMY responses since its whole thing is robust and rigorous SME level quality work. General testing all over.

# ü•ìü•¨üçÖ **BLT Framework README** üçÖü•¨ü•ì

Welcome to the **BLT** Framework‚Äîwhere modular logic meets AI flavor! Whether you‚Äôre cooking up some **BERTHA**, creative layering on a little **LORETTA**, or finishing with **TAMMY**‚Äôs juicy rigor, this README will guide you through a satisfying journey of structured prompt engineering and adaptive reasoning.

---

## ü•ì What‚Äôs in the BLT Sandwich?

**BLT** stands for **BERTHA**, **LORETTA**, and **TAMMY**‚Äîeach representing a modular layer you can invoke explicitly to enhance your AI interactions. Just like the perfect sandwich, each layer brings a unique flavor to the table:  
* **WILMA**: The white bread‚Äî**contextual driver** for a clean and organized bite.
* **BERTHA**: The hearty bacon‚Äî**prompt re-engineering** for clarity and focus.
* **LORETTA**: The creative lettuce‚Äî**layered reasoning and lateral thinking** for a crisp, fresh take.
* **TAMMY**: The juicy tomato‚Äî**rigorous, evidence-backed reasoning** to keep it real and reliable.

---

## ü•¨ How to Activate the BLT?

### **Explicit Tags** (No Implicit Layer Activation)

* `[BLT]`: Activates the whole sandwich‚ÄîBERTHA preprocessing plus either LORETTA or TAMMY for output.
* `[BERTHA]`: Bacon only‚Äîrefine the prompt for clarity.
* `[LORETTA]`: Lettuce only‚Äîlayer in creativity and cross-domain insights.
* `[TAMMY]`: Tomato only‚Äîrigorous, high-confidence, evidence-backed outputs.
* `[OFF]`: Back to baseline GPT‚Äîhold the bacon, lettuce, and tomato.
* `[RESET]`: Clears the plate‚Äîresets context and session memory.

üìù **Note**: Activation is one-shot per prompt‚Äîif you want another BLT, you‚Äôll have to order again (invoke the tag explicitly).

---

## üçÖ Framework Flavors at a Glance

| Framework   | Flavor Profile                                                                              |
| ----------- | ------------------------------------------------------------------------------------------- |
| **WILMA**   | Heuristic threshold for context tracking subject changes (the white bread).                 |
| **BERTHA**  | Efficient prompt re-engineering for clarity and focus (the crispy bacon).                   |
| **LORETTA** | Creative, cross-domain, lateral thinking‚Äîlayered and nuanced (the leafy lettuce).           |
| **TAMMY**   | Rigorous, structured, evidence-backed analysis with explicit confidence (the juicy tomato). |

---
## üçû WILMA: The White Bread - Automatically enforces an OFF behavior to recover baselineGPT (BLT framework deactivated, context preserved) with heuristic based subject change detection.
## ü•ì BERTHA: The Bacon Layer

**Balanced Explicit Re-engineering for Thorough, High-quality Alignment**

* Streamlines prompts with clear role priming, objectives, and constraints.
* Emphasizes minimal verbosity with maximal clarity‚Äîbecause soggy bacon ruins the sandwich.
* Compact re-engineering with options like:

  1. Proceed with refined prompt.
  2. Add cross-domain insights.
  3. Request further refinements.

üìù **Technical Edge**: Expect 35‚Äì50% efficiency gain in prompt predictability and structure.

---

## ü•¨ LORETTA: The Lettuce Layer

**Layered Output Refinement & Enhanced Thought Transformation**

* Modular, adaptive layers for:

  * General logical flow.
  * Domain-specific best practices.
  * Creative and cross-domain insights.
* Merges layers into a cohesive, engaging output‚Äîlike how lettuce keeps the sandwich fresh.
* Creative impact scored explicitly, with confidence calculations.

üìà **Creative Confidence**: System blending model probability and creative impact.

---

## üçÖ TAMMY: The Tomato Layer

**Technical Analysis Modular Methodology Yield Framework**

* High-stakes, precise output with logical rigor and confidence metrics.
* Structured sections:

  * Headline.
  * Evidence-backed reasoning.
  * Confidence score with rationale.
  * Self-audit checks.
  * Summary.
* Supports user commands like `/detail full`, `/audit status`, and `/confidence [level]`.

üîç **Precision Metrics**: Explicit calculations (API, but illusory otherwise) ensure evidence-supported reasoning, reducing hallucination risk.

---

## ü•™ Assembly Rules: One Sandwich at a Time

* **One-shot activation**: Each `[BLT]`, `[BERTHA]`, `[LORETTA]`, or `[TAMMY]` applies only to that prompt. New prompt = new sandwich.
* **Session resets**: Memory clears with `[RESET]`, and no auto-layer persistence.
* **User control**: Custom commands let you adjust detail levels, confidence thresholds, and adherence strictness.

---

## üöÄ Quick Start Example

Want to analyze AI in logistics with the full BLT?

```
Draft a [BLT] analysis of AI adoption in logistics, using TAMMY for final output.
```

Need just the bacon (BERTHA)?

```
Refine my prompt using [BERTHA].
```

Craving a creative salad (LORETTA)?

```
Give me a [LORETTA] style response for brainstorming.
```

---

## ü•ìü•¨üçÖ Final Thoughts

The **BLT Framework** isn‚Äôt just a tasty metaphor‚Äîit‚Äôs a robust, modular approach to AI reasoning. Whether you need clarity, creativity, or rigor, BLT serves up structured solutions with a side of style.
